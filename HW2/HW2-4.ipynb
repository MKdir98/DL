{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43944,"status":"ok","timestamp":1657448991879,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"},"user_tz":-270},"id":"4BG9EiphdiIb","outputId":"38e4eff4-7163-4fc7-82d0-888f5b3a96a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","training_file = '/content/drive/MyDrive/all/ML/Part4/kol.sher'\n","raw_text = open(training_file, 'r').read()\n","raw_text = raw_text.lower()\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1657448991881,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"},"user_tz":-270},"id":"vOys7-EhmNnq","outputId":"5500d7b8-c0d4-4c17-b243-59f252d1ca03"},"outputs":[{"output_type":"stream","name":"stdout","text":["ز شعر قدر و بها یافتند اگر شعرا\n","منم که شعر ز من یافته است قدر و بها\n","به پیش نادان گر قدر من بود پنهان\n","به پیش دانا باشد مقام من پیدا\n","همی نشاید گفتن که تیره شد خورشید\n","اگر نیاید روشن به دیده اعمی\n","شگفت نیس\n"]}],"source":["print(raw_text[:200])"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":549,"status":"ok","timestamp":1657448992407,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"},"user_tz":-270},"id":"UXucy-vKmUsB","outputId":"f82d7e8f-72bd-4d41-e891-0160f2275a11"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of unique words: 39065\n"]}],"source":["all_words = raw_text.split()\n","unique_words = list(set(all_words))\n","print(f'Number of unique words: {len(unique_words)}')\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47,"status":"ok","timestamp":1657448992408,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"},"user_tz":-270},"id":"hIX0wT4imaKG","outputId":"176a45e7-cefa-42ed-fdd2-ab364eccb5fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total characters: 2800509\n"]}],"source":["n_chars = len(raw_text)\n","print(f'Total characters: {n_chars}')\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1657448992409,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"},"user_tz":-270},"id":"Wb-g7Cw5meU5","outputId":"b3651733-aa3c-41c4-a5fb-ba523c40d6a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total vocabulary (unique characters): 62\n","['\\n', ' ', ',', '-', '=', '\\xa0', 'ء', 'آ', 'أ', 'ؤ', 'ا', 'ب', 'ة', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ل', 'م', 'ن', 'ه', 'و', 'ي', 'ٖ', '١', 'ٰ', 'ٱ', 'ٻ', 'پ', 'چ', 'ژ', 'ک', 'گ', 'ی', '۱', '۲', '۳', '\\u200b', '\\u200d', '\\u200e', '–', '’', 'ﭘ', 'ﺠ', 'ﻨ', 'ﻩ', 'ﻪ']\n"]}],"source":["chars = sorted(list(set(raw_text)))\n","n_vocab = len(chars)\n","print(f'Total vocabulary (unique characters): {n_vocab}')\n","print(chars)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1657448992410,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"},"user_tz":-270},"id":"d0g5Lt-tm7Sn","outputId":"7877b966-d923-4018-8b7d-dc506d14d459"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'\\n': 0, ' ': 1, ',': 2, '-': 3, '=': 4, '\\xa0': 5, 'ء': 6, 'آ': 7, 'أ': 8, 'ؤ': 9, 'ا': 10, 'ب': 11, 'ة': 12, 'ت': 13, 'ث': 14, 'ج': 15, 'ح': 16, 'خ': 17, 'د': 18, 'ذ': 19, 'ر': 20, 'ز': 21, 'س': 22, 'ش': 23, 'ص': 24, 'ض': 25, 'ط': 26, 'ظ': 27, 'ع': 28, 'غ': 29, 'ف': 30, 'ق': 31, 'ل': 32, 'م': 33, 'ن': 34, 'ه': 35, 'و': 36, 'ي': 37, 'ٖ': 38, '١': 39, 'ٰ': 40, 'ٱ': 41, 'ٻ': 42, 'پ': 43, 'چ': 44, 'ژ': 45, 'ک': 46, 'گ': 47, 'ی': 48, '۱': 49, '۲': 50, '۳': 51, '\\u200b': 52, '\\u200d': 53, '\\u200e': 54, '–': 55, '’': 56, 'ﭘ': 57, 'ﺠ': 58, 'ﻨ': 59, 'ﻩ': 60, 'ﻪ': 61}\n"]}],"source":["index_to_char = dict((i, c) for i, c in enumerate(chars))\n","char_to_index = dict((c, i) for i, c in enumerate(chars))\n","print(char_to_index)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1657448992410,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"},"user_tz":-270},"id":"kB54ttVznHTj"},"outputs":[],"source":["import numpy as np\n","seq_length = 160\n","n_seq = int(n_chars / seq_length)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":997,"status":"ok","timestamp":1657448993396,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"},"user_tz":-270},"id":"gp429xS5nW_O"},"outputs":[],"source":["X = np.zeros((n_seq, seq_length, n_vocab))\n","Y = np.zeros((n_seq, seq_length, n_vocab))\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":3120,"status":"ok","timestamp":1657448996511,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"},"user_tz":-270},"id":"gzEpE0dZoWhq"},"outputs":[],"source":["for i in range(n_seq):\n","  x_sequence = raw_text[i * seq_length : (i + 1) * seq_length]\n","  x_sequence_ohe = np.zeros((seq_length, n_vocab))\n","  for j in range(seq_length):\n","    char = x_sequence[j]\n","    index = char_to_index[char]\n","    x_sequence_ohe[j][index] = 1.\n","  X[i] = x_sequence_ohe\n","  y_sequence = raw_text[i * seq_length + 1 : (i + 1) * seq_length + 1] \n","  y_sequence_ohe = np.zeros((seq_length, n_vocab))\n","  for j in range(seq_length):\n","    try:\n","      char = y_sequence[j]\n","    except:\n","      # just for ignoring out of range error\n","      print('final sentence')\n","    index = char_to_index[char]\n","    y_sequence_ohe[j][index] = 1.\n","  Y[i] = y_sequence_ohe\n"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":2685,"status":"ok","timestamp":1657448999187,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"},"user_tz":-270},"id":"5oC-oggqraM5"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models, losses,optimizers\n","tf.random.set_seed(42)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1657448999188,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"},"user_tz":-270},"id":"PSVqjAJJreJC"},"outputs":[],"source":["hidden_units = 700\n","dropout = 0.4\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1657448999189,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"},"user_tz":-270},"id":"mlwuXDHbuGuV"},"outputs":[],"source":["batch_size = 100\n","n_epoch= 300"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":5291,"status":"ok","timestamp":1657449004471,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"},"user_tz":-270},"id":"1eMD5VDLuLXM"},"outputs":[],"source":["model = models.Sequential()\n","model.add(layers.LSTM(hidden_units, input_shape=(None, n_vocab), return_sequences=True, dropout=dropout))\n","model.add(layers.LSTM(hidden_units, return_sequences=True, dropout=dropout))\n","model.add(layers.TimeDistributed(layers.Dense(n_vocab, activation='softmax')))\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53,"status":"ok","timestamp":1657449004472,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"},"user_tz":-270},"id":"FsV8xRF0w5q1","outputId":"605d5181-6ce5-41ef-b6cd-f0f122b703ee"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]}],"source":["optimizer = optimizers.RMSprop(lr=0.001)\n","model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45,"status":"ok","timestamp":1657449004473,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"},"user_tz":-270},"id":"NT41ex1bw-cS","outputId":"be88eecc-c3fb-4798-b415-b84322b8fe75"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, None, 700)         2136400   \n","                                                                 \n"," lstm_1 (LSTM)               (None, None, 700)         3922800   \n","                                                                 \n"," time_distributed (TimeDistr  (None, None, 62)         43462     \n"," ibuted)                                                         \n","                                                                 \n","=================================================================\n","Total params: 6,102,662\n","Trainable params: 6,102,662\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}],"source":["print(model.summary())\n"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1657449004474,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"},"user_tz":-270},"id":"gYCwCgiHxYPX"},"outputs":[],"source":["from tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1657449004475,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"},"user_tz":-270},"id":"XviTsKdrxdTW"},"outputs":[],"source":["file_path = \"/content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_{epoch:03d}_loss_{loss:.4f}.hdf5\"\n","checkpoint = ModelCheckpoint(file_path, monitor='loss', verbose=1, save_best_only=True, mode='min')\n"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1657449004475,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"},"user_tz":-270},"id":"DzFddJz_xsd5"},"outputs":[],"source":["early_stop = EarlyStopping(monitor='loss', min_delta=0, patience=50, verbose=1, mode='min')\n"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1657449004477,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"},"user_tz":-270},"id":"1qVfJLszx04f"},"outputs":[],"source":["def generate_text(model, gen_length, n_vocab, index_to_char):\n","  index = np.random.randint(n_vocab)\n","  y_char = [index_to_char[index]]\n","  X = np.zeros((1, gen_length, n_vocab))\n","  for i in range(gen_length):\n","    X[0, i, index] = 1.\n","    indices = np.argmax(model.predict( X[:, max(0, i - seq_length -1):i + 1, :])[0], 1)\n","    index = indices[-1]\n","    y_char.append(index_to_char[index])\n","  return ''.join(y_char)\n","\n"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1657449004478,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"},"user_tz":-270},"id":"rA2lNqB7ypKn"},"outputs":[],"source":["class ResultChecker(Callback):\n","  def __init__(self, model, N, gen_length):\n","    self.model = model\n","    self.N = N\n","    self.gen_length = gen_length\n","    \n","  def on_epoch_end(self, epoch, logs={}):\n","    if epoch % self.N == 0:\n","      result = generate_text(self.model, self.gen_length, n_vocab, index_to_char)\n","      print('\\nMy War and Peace:\\n' + result)\n"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1657449004479,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"},"user_tz":-270},"id":"5FnTmq89zAcc"},"outputs":[],"source":["result_checker = ResultChecker(model, 10, 500)"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"khnwD9MxzI9e","executionInfo":{"status":"ok","timestamp":1657453835753,"user_tz":-270,"elapsed":4764429,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"}},"outputId":"729ed0e2-70f6-4e41-9ce0-d5d8b8889bd5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 202/300\n","  6/176 [>.............................] - ETA: 39s - loss: 2.0484WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0968s vs `on_train_batch_end` time: 0.1339s). Check your callbacks.\n","176/176 [==============================] - ETA: 0s - loss: 2.0360\n","Epoch 202: loss improved from inf to 2.03600, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_202_loss_2.0360.hdf5\n","176/176 [==============================] - 43s 242ms/step - loss: 2.0360\n","Epoch 203/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0339\n","Epoch 203: loss improved from 2.03600 to 2.03389, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_203_loss_2.0339.hdf5\n","176/176 [==============================] - 47s 265ms/step - loss: 2.0339\n","Epoch 204/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0342\n","Epoch 204: loss did not improve from 2.03389\n","176/176 [==============================] - 45s 257ms/step - loss: 2.0342\n","Epoch 205/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0338\n","Epoch 205: loss improved from 2.03389 to 2.03385, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_205_loss_2.0338.hdf5\n","176/176 [==============================] - 46s 259ms/step - loss: 2.0338\n","Epoch 206/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0334\n","Epoch 206: loss improved from 2.03385 to 2.03342, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_206_loss_2.0334.hdf5\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0334\n","Epoch 207/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0331\n","Epoch 207: loss improved from 2.03342 to 2.03315, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_207_loss_2.0331.hdf5\n","176/176 [==============================] - 46s 261ms/step - loss: 2.0331\n","Epoch 208/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0319\n","Epoch 208: loss improved from 2.03315 to 2.03191, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_208_loss_2.0319.hdf5\n","176/176 [==============================] - 45s 259ms/step - loss: 2.0319\n","Epoch 209/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0310\n","Epoch 209: loss improved from 2.03191 to 2.03096, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_209_loss_2.0310.hdf5\n","176/176 [==============================] - 46s 259ms/step - loss: 2.0310\n","Epoch 210/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0323\n","Epoch 210: loss did not improve from 2.03096\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0323\n","Epoch 211/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0328\n","My War and Peace:\n","و بر او بر سر آورد\n","به گرد خویشتن را بر سر آورد\n","به آن سنگ آمد آن سرو سیاهی\n","که بر در در نشاند آن گل بهانی\n","چو بر گردان شد از سر ناله ماه\n","به آن سرگشته رفت آن نالن شاه\n","چو شه در ساخت کار آن نال بر سنگ\n","به آن سنگ آمد آن شب را به تنگ\n","اگر چه بر سر خسرو نشستند\n","به آن در کار خود با بست شستند\n","به آن شیرین که آن شیرین نخواندند\n","به شیرین این سخن شاه جهان بود\n","که این مردان به در ان بر نبودند\n","به آن در مانده ای در پای بردند\n","به آن در کار کردن باز گردند\n","به آن در کار من بر ار کردند\n","چو شیرین دید کان مردان فرهنگ\n","که بر ما ب\n","\n","Epoch 211: loss did not improve from 2.03096\n","176/176 [==============================] - 73s 417ms/step - loss: 2.0328\n","Epoch 212/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0300\n","Epoch 212: loss improved from 2.03096 to 2.03003, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_212_loss_2.0300.hdf5\n","176/176 [==============================] - 47s 266ms/step - loss: 2.0300\n","Epoch 213/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0304\n","Epoch 213: loss did not improve from 2.03003\n","176/176 [==============================] - 45s 256ms/step - loss: 2.0304\n","Epoch 214/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0314\n","Epoch 214: loss did not improve from 2.03003\n","176/176 [==============================] - 46s 260ms/step - loss: 2.0314\n","Epoch 215/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0310\n","Epoch 215: loss did not improve from 2.03003\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0310\n","Epoch 216/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0298\n","Epoch 216: loss improved from 2.03003 to 2.02981, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_216_loss_2.0298.hdf5\n","176/176 [==============================] - 46s 259ms/step - loss: 2.0298\n","Epoch 217/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0298\n","Epoch 217: loss did not improve from 2.02981\n","176/176 [==============================] - 45s 257ms/step - loss: 2.0298\n","Epoch 218/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0290\n","Epoch 218: loss improved from 2.02981 to 2.02899, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_218_loss_2.0290.hdf5\n","176/176 [==============================] - 46s 259ms/step - loss: 2.0290\n","Epoch 219/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0302\n","Epoch 219: loss did not improve from 2.02899\n","176/176 [==============================] - 46s 259ms/step - loss: 2.0302\n","Epoch 220/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0286\n","Epoch 220: loss improved from 2.02899 to 2.02864, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_220_loss_2.0286.hdf5\n","176/176 [==============================] - 46s 260ms/step - loss: 2.0286\n","Epoch 221/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0281\n","My War and Peace:\n","م از در می برد به دام\n","به در این دام و دل اندازی باد\n","گر به دامان شود از راه نهان\n","با تو با این دل من بیش نهاد\n","گر به دار آید و با ما باشد\n","گر به دامان شود از دست عدوم\n","با تو با این دل من باشد باد\n","این چنین دار که بر ما به سراست\n","با تو با این همه را باز نیست\n","ما که با ما به جهان بی نبرد\n","به که از دیده به این بازی گرد\n","در به داد و به دل اندازی کرد\n","تا به کار آید و با ما باشد\n","به که از دیده به ما باشد\n","باز از این بیش به بازی باشد\n","به که از دیده به ما باشد\n","با تو با این دل من بازی نیست\n","این چه باشد که به جای اندازید\n","\n","Epoch 221: loss improved from 2.02864 to 2.02809, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_221_loss_2.0281.hdf5\n","176/176 [==============================] - 72s 409ms/step - loss: 2.0281\n","Epoch 222/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0275\n","Epoch 222: loss improved from 2.02809 to 2.02748, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_222_loss_2.0275.hdf5\n","176/176 [==============================] - 47s 266ms/step - loss: 2.0275\n","Epoch 223/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0275\n","Epoch 223: loss did not improve from 2.02748\n","176/176 [==============================] - 45s 256ms/step - loss: 2.0275\n","Epoch 224/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0276\n","Epoch 224: loss did not improve from 2.02748\n","176/176 [==============================] - 46s 259ms/step - loss: 2.0276\n","Epoch 225/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0264\n","Epoch 225: loss improved from 2.02748 to 2.02640, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_225_loss_2.0264.hdf5\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0264\n","Epoch 226/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0266\n","Epoch 226: loss did not improve from 2.02640\n","176/176 [==============================] - 46s 259ms/step - loss: 2.0266\n","Epoch 227/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0268\n","Epoch 227: loss did not improve from 2.02640\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0268\n","Epoch 228/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0280\n","Epoch 228: loss did not improve from 2.02640\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0280\n","Epoch 229/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0238\n","Epoch 229: loss improved from 2.02640 to 2.02382, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_229_loss_2.0238.hdf5\n","176/176 [==============================] - 46s 259ms/step - loss: 2.0238\n","Epoch 230/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0256\n","Epoch 230: loss did not improve from 2.02382\n","176/176 [==============================] - 45s 257ms/step - loss: 2.0256\n","Epoch 231/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0241\n","My War and Peace:\n","م از در دو سو بر سر آرد\n","به در این دایره دیر است و به ما با دارد\n","به که از دست عوام\n","در من از دست عوام\n","ای پس از من و تو مرده ای از من باشد\n","گر به دست او بگذاریم و به ما با دارد\n","دل من با تو من از دور به افتادی باد\n","با تو در عاشق و دین ما نگرد در بر خویش\n","با تو در دل نه من از دور به ای ما باشد\n","گر به دست تو برون آید و بر ما باشد\n","به که با ما به سر ما به من آید با سر\n","به سر ما به سر اندر نکند مرد بروش\n","با چنین حال به ما با تو به ما با دارد\n","به که با ما به سر اندر نظر افتد با سر\n","بر سر این دل نالان و نه از دست ب\n","\n","Epoch 231: loss did not improve from 2.02382\n","176/176 [==============================] - 72s 408ms/step - loss: 2.0241\n","Epoch 232/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0231\n","Epoch 232: loss improved from 2.02382 to 2.02311, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_232_loss_2.0231.hdf5\n","176/176 [==============================] - 47s 265ms/step - loss: 2.0231\n","Epoch 233/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0241\n","Epoch 233: loss did not improve from 2.02311\n","176/176 [==============================] - 45s 256ms/step - loss: 2.0241\n","Epoch 234/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0232\n","Epoch 234: loss did not improve from 2.02311\n","176/176 [==============================] - 46s 259ms/step - loss: 2.0232\n","Epoch 235/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0233\n","Epoch 235: loss did not improve from 2.02311\n","176/176 [==============================] - 45s 256ms/step - loss: 2.0233\n","Epoch 236/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0234\n","Epoch 236: loss did not improve from 2.02311\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0234\n","Epoch 237/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0247\n","Epoch 237: loss did not improve from 2.02311\n","176/176 [==============================] - 46s 260ms/step - loss: 2.0247\n","Epoch 238/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0198\n","Epoch 238: loss improved from 2.02311 to 2.01983, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_238_loss_2.0198.hdf5\n","176/176 [==============================] - 46s 259ms/step - loss: 2.0198\n","Epoch 239/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0227\n","Epoch 239: loss did not improve from 2.01983\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0227\n","Epoch 240/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0224\n","Epoch 240: loss did not improve from 2.01983\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0224\n","Epoch 241/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0212\n","My War and Peace:\n","ﻩ بر در او باز کرد\n","به اندازه ای که در آن داوری\n","که با او به دریا درآویختی\n","به آن گنج ان کان نماند به رای\n","که بر داوری کار باید نهاد\n","به اندازه ای کان نوازد به چنگ\n","که با دور او باشد آن راه گنج\n","چو در خار خالی کشیدم به چنگ\n","به گنجی درآمد به گردن سنگ\n","به گنجینه ای کان برافروختم\n","به گنجی هم آن گنج و آن خوختم\n","چو در گنج خانه بر انداختم\n","ز بس گنج پندان به گرداختم\n","بر آن گنج و از گنج و گنجی به چنگ\n","که با من به دریا درآرد به چنگ\n","چو در مار می گنج دانی کشید\n","به در دانش اندازی اندیشه کید\n","به آن گنج و ان کار با در نهفت\n","که\n","\n","Epoch 241: loss did not improve from 2.01983\n","176/176 [==============================] - 71s 407ms/step - loss: 2.0212\n","Epoch 242/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0208\n","Epoch 242: loss did not improve from 2.01983\n","176/176 [==============================] - 47s 265ms/step - loss: 2.0208\n","Epoch 243/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0208\n","Epoch 243: loss did not improve from 2.01983\n","176/176 [==============================] - 45s 256ms/step - loss: 2.0208\n","Epoch 244/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0207\n","Epoch 244: loss did not improve from 2.01983\n","176/176 [==============================] - 46s 260ms/step - loss: 2.0207\n","Epoch 245/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0216\n","Epoch 245: loss did not improve from 2.01983\n","176/176 [==============================] - 45s 257ms/step - loss: 2.0216\n","Epoch 246/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0205\n","Epoch 246: loss did not improve from 2.01983\n","176/176 [==============================] - 46s 259ms/step - loss: 2.0205\n","Epoch 247/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0196\n","Epoch 247: loss improved from 2.01983 to 2.01958, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_247_loss_2.0196.hdf5\n","176/176 [==============================] - 46s 259ms/step - loss: 2.0196\n","Epoch 248/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0190\n","Epoch 248: loss improved from 2.01958 to 2.01898, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_248_loss_2.0190.hdf5\n","176/176 [==============================] - 45s 259ms/step - loss: 2.0190\n","Epoch 249/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0197\n","Epoch 249: loss did not improve from 2.01898\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0197\n","Epoch 250/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0187\n","Epoch 250: loss improved from 2.01898 to 2.01874, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_250_loss_2.0187.hdf5\n","176/176 [==============================] - 46s 259ms/step - loss: 2.0187\n","Epoch 251/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0209\n","My War and Peace:\n","۳ بر او به در نهاده\n","از دور دل از در اوفتاده\n","در مرده که ما که در نهادی\n","از در در مو نه در نهاده\n","می کرد ز روی دور در پیش\n","در پیش فکنده چون تو خویش\n","از دیده که در جهان فرازی\n","بر داد فرا چه داد دارد\n","می کوش که این سخن نشانی\n","می کرد به جای خویش خانی\n","از کیه که باد خویش بیداد\n","بر خواند ازین خری ندادی\n","در خواب نیاز و داد خاری\n","کان شیفته را به سر نشادن\n","بر خاک زدی به روی داده\n","می کرد ز روی خویش پوشی\n","می کرد به روی خویش پوشی\n","از کرده که در جهان فرازی\n","با او به سرش نشان ناری\n","از راه که بر سرش نشیند\n","از راه نوان به جای خویش\n","\n","Epoch 251: loss did not improve from 2.01874\n","176/176 [==============================] - 72s 408ms/step - loss: 2.0209\n","Epoch 252/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0187\n","Epoch 252: loss improved from 2.01874 to 2.01871, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_252_loss_2.0187.hdf5\n","176/176 [==============================] - 47s 265ms/step - loss: 2.0187\n","Epoch 253/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0156\n","Epoch 253: loss improved from 2.01871 to 2.01563, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_253_loss_2.0156.hdf5\n","176/176 [==============================] - 45s 255ms/step - loss: 2.0156\n","Epoch 254/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0196\n","Epoch 254: loss did not improve from 2.01563\n","176/176 [==============================] - 46s 260ms/step - loss: 2.0196\n","Epoch 255/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0143\n","Epoch 255: loss improved from 2.01563 to 2.01426, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_255_loss_2.0143.hdf5\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0143\n","Epoch 256/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0177\n","Epoch 256: loss did not improve from 2.01426\n","176/176 [==============================] - 45s 259ms/step - loss: 2.0177\n","Epoch 257/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0159\n","Epoch 257: loss did not improve from 2.01426\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0159\n","Epoch 258/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0160\n","Epoch 258: loss did not improve from 2.01426\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0160\n","Epoch 259/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0156\n","Epoch 259: loss did not improve from 2.01426\n","176/176 [==============================] - 45s 259ms/step - loss: 2.0156\n","Epoch 260/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0156\n","Epoch 260: loss did not improve from 2.01426\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0156\n","Epoch 261/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0158\n","My War and Peace:\n","که با من بر او باز نیست\n","به این داوری کار ای این نیست\n","به این داستان را نیاید به جای\n","که بر من به من با تو بیدار نیست\n","به من بی که با من به جان منست\n","به دار آمدن می کنم در نهفت\n","به من دان که این خانه را باز نیست\n","به بازی در این دار دیوانه نیست\n","به من دان که در خورد این کار نیست\n","به من بین و بی خواب و خار من نیست\n","به من دان که در خورد این خانه راست\n","به من با که با من به جان من نبود\n","به من با که با من به جان منست\n","به دار آمد و دیده بی ای نیست\n","به من با که با من به جان می نیست\n","به دارا در این دار و بی ما نه سیم\n","چو\n","\n","Epoch 261: loss did not improve from 2.01426\n","176/176 [==============================] - 71s 405ms/step - loss: 2.0158\n","Epoch 262/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0144\n","Epoch 262: loss did not improve from 2.01426\n","176/176 [==============================] - 47s 264ms/step - loss: 2.0144\n","Epoch 263/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0145\n","Epoch 263: loss did not improve from 2.01426\n","176/176 [==============================] - 45s 255ms/step - loss: 2.0145\n","Epoch 264/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0157\n","Epoch 264: loss did not improve from 2.01426\n","176/176 [==============================] - 46s 260ms/step - loss: 2.0157\n","Epoch 265/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0139\n","Epoch 265: loss improved from 2.01426 to 2.01394, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_265_loss_2.0139.hdf5\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0139\n","Epoch 266/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0140\n","Epoch 266: loss did not improve from 2.01394\n","176/176 [==============================] - 46s 259ms/step - loss: 2.0140\n","Epoch 267/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0154\n","Epoch 267: loss did not improve from 2.01394\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0154\n","Epoch 268/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0142\n","Epoch 268: loss did not improve from 2.01394\n","176/176 [==============================] - 45s 257ms/step - loss: 2.0142\n","Epoch 269/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0132\n","Epoch 269: loss improved from 2.01394 to 2.01321, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_269_loss_2.0132.hdf5\n","176/176 [==============================] - 45s 259ms/step - loss: 2.0132\n","Epoch 270/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0144\n","Epoch 270: loss did not improve from 2.01321\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0144\n","Epoch 271/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0140\n","My War and Peace:\n","۲ بر در این سان به باد\n","با تو به من بر که به جان آورد\n","با سر این راه که بازی کند\n","با سر این راه که بازی دهد\n","گر نفسی با سر این راه شد\n","گر به تو بر خاک بود پای تو\n","با تو نظامی به جهان تا بتوزدی تو به تو باد به دام آوری\n","تا نه به تو با تو به تو باز کرد\n","تا نکنی با تو به تو باز کرد\n","تا نکنی عالم این راز تست\n","با تو نظامی به جوانی درست\n","تا نکنی با تو به تو با کسی\n","با تو نظامی به که بازی کنی\n","خان به نو کرده به بازی دهد\n","گر نفسی با تو براند کسی\n","خانه کن این خاک به بازی بسی\n","گر نفسی عاشق خود را کشی\n","گر نفسی عاشق خود را ک\n","\n","Epoch 271: loss did not improve from 2.01321\n","176/176 [==============================] - 71s 407ms/step - loss: 2.0140\n","Epoch 272/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0116\n","Epoch 272: loss improved from 2.01321 to 2.01165, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_272_loss_2.0116.hdf5\n","176/176 [==============================] - 47s 265ms/step - loss: 2.0116\n","Epoch 273/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0124\n","Epoch 273: loss did not improve from 2.01165\n","176/176 [==============================] - 45s 255ms/step - loss: 2.0124\n","Epoch 274/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0126\n","Epoch 274: loss did not improve from 2.01165\n","176/176 [==============================] - 46s 259ms/step - loss: 2.0126\n","Epoch 275/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0101\n","Epoch 275: loss improved from 2.01165 to 2.01008, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_275_loss_2.0101.hdf5\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0101\n","Epoch 276/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0114\n","Epoch 276: loss did not improve from 2.01008\n","176/176 [==============================] - 46s 259ms/step - loss: 2.0114\n","Epoch 277/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0087\n","Epoch 277: loss improved from 2.01008 to 2.00871, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_277_loss_2.0087.hdf5\n","176/176 [==============================] - 46s 260ms/step - loss: 2.0087\n","Epoch 278/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0104\n","Epoch 278: loss did not improve from 2.00871\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0104\n","Epoch 279/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0094\n","Epoch 279: loss did not improve from 2.00871\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0094\n","Epoch 280/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0102\n","Epoch 280: loss did not improve from 2.00871\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0102\n","Epoch 281/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0101\n","My War and Peace:\n","ﻪ به دو داده ای به دام و به می\n","به که به من به می نه دیده ام\n","به که در خواب خود نباشم و بس\n","من که در من به من به داد و به تس\n","به که در خواب خود نباشم خام\n","هم به تو باد و تو ندارم تو\n","چون در آن داوری که دارم تو\n","چون به تو دور داد تا به تو باد\n","تا به تو باد تو به تو به باد\n","چون در این داستان خود به تو باد\n","تا به تو باد تو به تو به باد\n","چون در این داستان خوش بردم\n","با تو دو تو به تو به تو بودم\n","گر به تو با تو باد دادم تو\n","به که با من به تو به تو تو تو\n","تو که داری ز تو به جان تو باد\n","تا تو با تو به تو به تو باد\n","با تو\n","\n","Epoch 281: loss did not improve from 2.00871\n","176/176 [==============================] - 71s 403ms/step - loss: 2.0101\n","Epoch 282/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0093\n","Epoch 282: loss did not improve from 2.00871\n","176/176 [==============================] - 47s 264ms/step - loss: 2.0093\n","Epoch 283/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0075\n","Epoch 283: loss improved from 2.00871 to 2.00753, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_283_loss_2.0075.hdf5\n","176/176 [==============================] - 45s 257ms/step - loss: 2.0075\n","Epoch 284/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0081\n","Epoch 284: loss did not improve from 2.00753\n","176/176 [==============================] - 46s 261ms/step - loss: 2.0081\n","Epoch 285/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0070\n","Epoch 285: loss improved from 2.00753 to 2.00705, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_285_loss_2.0070.hdf5\n","176/176 [==============================] - 46s 259ms/step - loss: 2.0070\n","Epoch 286/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0081\n","Epoch 286: loss did not improve from 2.00705\n","176/176 [==============================] - 46s 259ms/step - loss: 2.0081\n","Epoch 287/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0097\n","Epoch 287: loss did not improve from 2.00705\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0097\n","Epoch 288/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0087\n","Epoch 288: loss did not improve from 2.00705\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0087\n","Epoch 289/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0082\n","Epoch 289: loss did not improve from 2.00705\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0082\n","Epoch 290/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0079\n","Epoch 290: loss did not improve from 2.00705\n","176/176 [==============================] - 46s 259ms/step - loss: 2.0079\n","Epoch 291/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0069\n","My War and Peace:\n","ء الله این چه رنگ است\n","سبحان الله این چه رنگ است\n","گفتند که جای گفت  این کار\n","با من نگرم به من کند رار\n","این مرغ سخن به من برآیم\n","این بار به من برون نمایم\n","گفتند که ما کنام جانست\n","این بیت برا نیاید از سست\n","گر من نگرم به خانه خویش\n","کان دارم و با تو می خور آییش\n","گر در دل من نه بی نیازی\n","بر من به چنان براز گاری\n","کان دید که این سخن بران داد\n","بر خواند خویش نامداران\n","در خواند نشان و خواب خوشان\n","چون بر سر خور بر شکر شد\n","با او به نخست بر گرفتند\n","بر روی به روز باز گفتند\n","بر روی به روز باز می گشت\n","بر خورد و به روز می گشاد درت\n","\n","\n","Epoch 291: loss improved from 2.00705 to 2.00685, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_291_loss_2.0069.hdf5\n","176/176 [==============================] - 71s 406ms/step - loss: 2.0069\n","Epoch 292/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0062\n","Epoch 292: loss improved from 2.00685 to 2.00623, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_292_loss_2.0062.hdf5\n","176/176 [==============================] - 47s 265ms/step - loss: 2.0062\n","Epoch 293/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0083\n","Epoch 293: loss did not improve from 2.00623\n","176/176 [==============================] - 45s 254ms/step - loss: 2.0083\n","Epoch 294/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0066\n","Epoch 294: loss did not improve from 2.00623\n","176/176 [==============================] - 46s 260ms/step - loss: 2.0066\n","Epoch 295/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0054\n","Epoch 295: loss improved from 2.00623 to 2.00538, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_295_loss_2.0054.hdf5\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0054\n","Epoch 296/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0054\n","Epoch 296: loss did not improve from 2.00538\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0054\n","Epoch 297/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0055\n","Epoch 297: loss did not improve from 2.00538\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0055\n","Epoch 298/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0066\n","Epoch 298: loss did not improve from 2.00538\n","176/176 [==============================] - 45s 257ms/step - loss: 2.0066\n","Epoch 299/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0042\n","Epoch 299: loss improved from 2.00538 to 2.00422, saving model to /content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_299_loss_2.0042.hdf5\n","176/176 [==============================] - 46s 260ms/step - loss: 2.0042\n","Epoch 300/300\n","176/176 [==============================] - ETA: 0s - loss: 2.0042\n","Epoch 300: loss did not improve from 2.00422\n","176/176 [==============================] - 45s 258ms/step - loss: 2.0042\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f98ec1a8450>"]},"metadata":{},"execution_count":24}],"source":["model.load_weights(\"/content/drive/MyDrive/all/ML/Part4/weights/weights_epoch_202_loss_2.0341.hdf5\")\n","model.fit(X, Y, batch_size=batch_size, verbose=1, initial_epoch=201, epochs=n_epoch, callbacks=[result_checker, checkpoint, early_stop])\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"HW2-4.ipynb","provenance":[],"authorship_tag":"ABX9TyMOFE62O9Ds07p696615LXd"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}