{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN5yN5Zw0U9iAPMdOxYkuEQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"4BG9EiphdiIb","executionInfo":{"status":"ok","timestamp":1656924138642,"user_tz":-270,"elapsed":3371,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c3844e67-edd6-411c-e539-39d79d250110"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","training_file = '/content/drive/MyDrive/all/ML/warpeace_input.txt'\n","raw_text = open(training_file, 'r').read()\n","raw_text = raw_text.lower()\n"]},{"cell_type":"code","source":["print(raw_text[:200])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vOys7-EhmNnq","executionInfo":{"status":"ok","timestamp":1656924139215,"user_tz":-270,"elapsed":577,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"}},"outputId":"fd436677-5816-49b4-985e-2edcfa4a1802"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["﻿the project gutenberg ebook of war and peace, by leo tolstoy\n","\n","this ebook is for the use of anyone anywhere in the united states and\n","most other parts of the world at no cost and with almost no restric\n"]}]},{"cell_type":"code","source":["all_words = raw_text.split()\n","unique_words = list(set(all_words))\n","print(f'Number of unique words: {len(unique_words)}')\n"],"metadata":{"id":"UXucy-vKmUsB","executionInfo":{"status":"ok","timestamp":1656924139217,"user_tz":-270,"elapsed":28,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8d2b8992-7d8e-40cf-d027-2a27629488e5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of unique words: 40114\n"]}]},{"cell_type":"code","source":["n_chars = len(raw_text)\n","print(f'Total characters: {n_chars}')\n"],"metadata":{"id":"hIX0wT4imaKG","executionInfo":{"status":"ok","timestamp":1656924139217,"user_tz":-270,"elapsed":24,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f34b0993-1460-494c-92ad-d024659d4ac8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Total characters: 3227520\n"]}]},{"cell_type":"code","source":["chars = sorted(list(set(raw_text)))\n","n_vocab = len(chars)\n","print(f'Total vocabulary (unique characters): {n_vocab}')\n","print(chars)\n"],"metadata":{"id":"Wb-g7Cw5meU5","executionInfo":{"status":"ok","timestamp":1656924139218,"user_tz":-270,"elapsed":18,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"871bee20-11e1-4495-bf4a-986788f00c7b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Total vocabulary (unique characters): 83\n","['\\n', ' ', '!', '\"', '#', '$', '%', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'à', 'á', 'â', 'ä', 'æ', 'ç', 'è', 'é', 'ê', 'ë', 'í', 'î', 'ï', 'ó', 'ô', 'ö', 'ú', 'ü', 'ý', 'œ', '—', '‘', '’', '“', '”', '\\ufeff']\n"]}]},{"cell_type":"code","source":["index_to_char = dict((i, c) for i, c in enumerate(chars))\n","char_to_index = dict((c, i) for i, c in enumerate(chars))\n","print(char_to_index)\n"],"metadata":{"id":"d0g5Lt-tm7Sn","executionInfo":{"status":"ok","timestamp":1656924139219,"user_tz":-270,"elapsed":16,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6fc5c4b2-70c4-45bf-a2e5-aa4ce59efad9"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '#': 4, '$': 5, '%': 6, \"'\": 7, '(': 8, ')': 9, '*': 10, ',': 11, '-': 12, '.': 13, '/': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, ';': 26, '=': 27, '?': 28, '[': 29, ']': 30, 'a': 31, 'b': 32, 'c': 33, 'd': 34, 'e': 35, 'f': 36, 'g': 37, 'h': 38, 'i': 39, 'j': 40, 'k': 41, 'l': 42, 'm': 43, 'n': 44, 'o': 45, 'p': 46, 'q': 47, 'r': 48, 's': 49, 't': 50, 'u': 51, 'v': 52, 'w': 53, 'x': 54, 'y': 55, 'z': 56, 'à': 57, 'á': 58, 'â': 59, 'ä': 60, 'æ': 61, 'ç': 62, 'è': 63, 'é': 64, 'ê': 65, 'ë': 66, 'í': 67, 'î': 68, 'ï': 69, 'ó': 70, 'ô': 71, 'ö': 72, 'ú': 73, 'ü': 74, 'ý': 75, 'œ': 76, '—': 77, '‘': 78, '’': 79, '“': 80, '”': 81, '\\ufeff': 82}\n"]}]},{"cell_type":"code","source":["import numpy as np\n","seq_length = 160\n","n_seq = int(n_chars / seq_length)\n"],"metadata":{"id":"kB54ttVznHTj","executionInfo":{"status":"ok","timestamp":1656924139219,"user_tz":-270,"elapsed":12,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["X = np.zeros((n_seq, seq_length, n_vocab))\n","Y = np.zeros((n_seq, seq_length, n_vocab))\n"],"metadata":{"id":"gp429xS5nW_O","executionInfo":{"status":"ok","timestamp":1656924142456,"user_tz":-270,"elapsed":3248,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["for i in range(n_seq):\n","  x_sequence = raw_text[i * seq_length : (i + 1) * seq_length]\n","  x_sequence_ohe = np.zeros((seq_length, n_vocab))\n","  for j in range(seq_length):\n","    char = x_sequence[j]\n","    index = char_to_index[char]\n","    x_sequence_ohe[j][index] = 1.\n","  X[i] = x_sequence_ohe\n","  y_sequence = raw_text[i * seq_length + 1 : (i + 1) * seq_length + 1] \n","  y_sequence_ohe = np.zeros((seq_length, n_vocab))\n","  for j in range(seq_length):\n","    try:\n","      char = y_sequence[j]\n","    except:\n","      # just for ignoring out of range error\n","      print('final sentence')\n","    index = char_to_index[char]\n","    y_sequence_ohe[j][index] = 1.\n","  Y[i] = y_sequence_ohe\n"],"metadata":{"id":"gzEpE0dZoWhq","executionInfo":{"status":"ok","timestamp":1656924146592,"user_tz":-270,"elapsed":4156,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f7ae1f72-dbce-44f2-a7c0-bff874a06762"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["final sentence\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras import layers, models, losses,optimizers\n","tf.random.set_seed(42)\n"],"metadata":{"id":"5oC-oggqraM5","executionInfo":{"status":"ok","timestamp":1656924153475,"user_tz":-270,"elapsed":6904,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["hidden_units = 700\n","dropout = 0.4\n"],"metadata":{"id":"PSVqjAJJreJC","executionInfo":{"status":"ok","timestamp":1656924153477,"user_tz":-270,"elapsed":25,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["batch_size = 100\n","n_epoch= 300"],"metadata":{"id":"mlwuXDHbuGuV","executionInfo":{"status":"ok","timestamp":1656924153478,"user_tz":-270,"elapsed":23,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["model = models.Sequential()\n","model.add(layers.LSTM(hidden_units, input_shape=(None, n_vocab), return_sequences=True, dropout=dropout))\n","model.add(layers.LSTM(hidden_units, return_sequences=True, dropout=dropout))\n","model.add(layers.TimeDistributed(layers.Dense(n_vocab, activation='softmax')))\n"],"metadata":{"id":"1eMD5VDLuLXM","executionInfo":{"status":"ok","timestamp":1656924158324,"user_tz":-270,"elapsed":4868,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["optimizer = optimizers.RMSprop(lr=0.001)\n","model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)\n"],"metadata":{"id":"FsV8xRF0w5q1","executionInfo":{"status":"ok","timestamp":1656924158324,"user_tz":-270,"elapsed":38,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4c9c514d-180d-4b0d-8790-57ac6037d821"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]}]},{"cell_type":"code","source":["print(model.summary())\n"],"metadata":{"id":"NT41ex1bw-cS","executionInfo":{"status":"ok","timestamp":1656924158325,"user_tz":-270,"elapsed":33,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ee9ecceb-95f8-4bbf-d4da-615527d3bba2"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, None, 700)         2195200   \n","                                                                 \n"," lstm_1 (LSTM)               (None, None, 700)         3922800   \n","                                                                 \n"," time_distributed (TimeDistr  (None, None, 83)         58183     \n"," ibuted)                                                         \n","                                                                 \n","=================================================================\n","Total params: 6,176,183\n","Trainable params: 6,176,183\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n"],"metadata":{"id":"gYCwCgiHxYPX","executionInfo":{"status":"ok","timestamp":1656924158325,"user_tz":-270,"elapsed":24,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["file_path = \"/content/drive/MyDrive/all/ML/weights/weights_epoch_{epoch:03d}_loss_{loss:.4f}.hdf5\"\n","checkpoint = ModelCheckpoint(file_path, monitor='loss', verbose=1, save_best_only=True, mode='min')\n"],"metadata":{"id":"XviTsKdrxdTW","executionInfo":{"status":"ok","timestamp":1656924158326,"user_tz":-270,"elapsed":24,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["early_stop = EarlyStopping(monitor='loss', min_delta=0, patience=50, verbose=1, mode='min')\n"],"metadata":{"id":"DzFddJz_xsd5","executionInfo":{"status":"ok","timestamp":1656924158326,"user_tz":-270,"elapsed":24,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def generate_text(model, gen_length, n_vocab, index_to_char):\n","  index = np.random.randint(n_vocab)\n","  y_char = [index_to_char[index]]\n","  X = np.zeros((1, gen_length, n_vocab))\n","  for i in range(gen_length):\n","    X[0, i, index] = 1.\n","    indices = np.argmax(model.predict( X[:, max(0, i - seq_length -1):i + 1, :])[0], 1)\n","    index = indices[-1]\n","    y_char.append(index_to_char[index])\n","  return ''.join(y_char)\n","\n"],"metadata":{"id":"1qVfJLszx04f","executionInfo":{"status":"ok","timestamp":1656924158327,"user_tz":-270,"elapsed":24,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["class ResultChecker(Callback):\n","  def __init__(self, model, N, gen_length):\n","    self.model = model\n","    self.N = N\n","    self.gen_length = gen_length\n","    \n","  def on_epoch_end(self, epoch, logs={}):\n","    if epoch % self.N == 0:\n","      result = generate_text(self.model, self.gen_length, n_vocab, index_to_char)\n","      print('\\nMy War and Peace:\\n' + result)\n"],"metadata":{"id":"rA2lNqB7ypKn","executionInfo":{"status":"ok","timestamp":1656924158327,"user_tz":-270,"elapsed":24,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["result_checker = ResultChecker(model, 10, 500)"],"metadata":{"id":"5FnTmq89zAcc","executionInfo":{"status":"ok","timestamp":1656924158328,"user_tz":-270,"elapsed":25,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["model.load_weights(\"/content/drive/MyDrive/all/ML/weights/weights_epoch_244_loss_1.6163.hdf5\")\n","model.fit(X, Y, batch_size=batch_size, verbose=1, initial_epoch=244, epochs=n_epoch, callbacks=[result_checker, checkpoint, early_stop])\n"],"metadata":{"id":"khnwD9MxzI9e","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d5042f15-e795-49c3-e8af-ddd1626d49b1","executionInfo":{"status":"ok","timestamp":1656927406002,"user_tz":-270,"elapsed":3247698,"user":{"displayName":"mahdi karami","userId":"04971533198241835395"}}},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 245/300\n","  6/202 [..............................] - ETA: 47s - loss: 1.6306WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0962s vs `on_train_batch_end` time: 0.1360s). Check your callbacks.\n","202/202 [==============================] - ETA: 0s - loss: 1.6179\n","Epoch 245: loss improved from inf to 1.61785, saving model to /content/drive/MyDrive/all/ML/weights/weights_epoch_245_loss_1.6179.hdf5\n","202/202 [==============================] - 56s 255ms/step - loss: 1.6179\n","Epoch 246/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6194\n","Epoch 246: loss did not improve from 1.61785\n","202/202 [==============================] - 56s 278ms/step - loss: 1.6194\n","Epoch 247/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6196\n","Epoch 247: loss did not improve from 1.61785\n","202/202 [==============================] - 55s 271ms/step - loss: 1.6196\n","Epoch 248/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6173\n","Epoch 248: loss improved from 1.61785 to 1.61729, saving model to /content/drive/MyDrive/all/ML/weights/weights_epoch_248_loss_1.6173.hdf5\n","202/202 [==============================] - 56s 275ms/step - loss: 1.6173\n","Epoch 249/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6162\n","Epoch 249: loss improved from 1.61729 to 1.61622, saving model to /content/drive/MyDrive/all/ML/weights/weights_epoch_249_loss_1.6162.hdf5\n","202/202 [==============================] - 56s 275ms/step - loss: 1.6162\n","Epoch 250/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6179\n","Epoch 250: loss did not improve from 1.61622\n","202/202 [==============================] - 55s 275ms/step - loss: 1.6179\n","Epoch 251/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6160\n","My War and Peace:\n","re was a stranger and more animated and intelligent. the countess was sitting in the same place with her handkerchief to her heart and she was sitting in the same place with her handkerchief to her heart. she was sitting in the same place with her handkerchief to her heart and the same strange smile of her face was struck by the same expression of her face and she was so strange that she was always the same to her and her father would not be able to see her and her father would not be able to see\n","\n","Epoch 251: loss improved from 1.61622 to 1.61598, saving model to /content/drive/MyDrive/all/ML/weights/weights_epoch_251_loss_1.6160.hdf5\n","202/202 [==============================] - 85s 422ms/step - loss: 1.6160\n","Epoch 252/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6158\n","Epoch 252: loss improved from 1.61598 to 1.61576, saving model to /content/drive/MyDrive/all/ML/weights/weights_epoch_252_loss_1.6158.hdf5\n","202/202 [==============================] - 57s 281ms/step - loss: 1.6158\n","Epoch 253/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6159\n","Epoch 253: loss did not improve from 1.61576\n","202/202 [==============================] - 55s 272ms/step - loss: 1.6159\n","Epoch 254/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6165\n","Epoch 254: loss did not improve from 1.61576\n","202/202 [==============================] - 55s 274ms/step - loss: 1.6165\n","Epoch 255/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6158\n","Epoch 255: loss did not improve from 1.61576\n","202/202 [==============================] - 55s 275ms/step - loss: 1.6158\n","Epoch 256/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6149\n","Epoch 256: loss improved from 1.61576 to 1.61490, saving model to /content/drive/MyDrive/all/ML/weights/weights_epoch_256_loss_1.6149.hdf5\n","202/202 [==============================] - 55s 274ms/step - loss: 1.6149\n","Epoch 257/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6140\n","Epoch 257: loss improved from 1.61490 to 1.61395, saving model to /content/drive/MyDrive/all/ML/weights/weights_epoch_257_loss_1.6140.hdf5\n","202/202 [==============================] - 55s 274ms/step - loss: 1.6140\n","Epoch 258/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6153\n","Epoch 258: loss did not improve from 1.61395\n","202/202 [==============================] - 56s 275ms/step - loss: 1.6153\n","Epoch 259/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6146\n","Epoch 259: loss did not improve from 1.61395\n","202/202 [==============================] - 56s 275ms/step - loss: 1.6146\n","Epoch 260/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6136\n","Epoch 260: loss improved from 1.61395 to 1.61359, saving model to /content/drive/MyDrive/all/ML/weights/weights_epoch_260_loss_1.6136.hdf5\n","202/202 [==============================] - 56s 276ms/step - loss: 1.6136\n","Epoch 261/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6150\n","My War and Peace:\n","‘i have not yet got a little for the first time and i have not been to the room and will be an answer.”\n","\n","“i know you will see that i should like to say that i have not yet\n","seen to me and i have not yet gone to ask you to do so.”\n","\n","“i will tell you that i have not yet and wish to say so,” said\n","prince andrew.\n","\n","“i have not yet known him anything,” said prince andrew, “i have not\n","been to the left flank and will be a bad to the emperor. i have not\n","the least to say that i have not the least for a yone t\n","\n","Epoch 261: loss did not improve from 1.61359\n","202/202 [==============================] - 82s 407ms/step - loss: 1.6150\n","Epoch 262/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6127\n","Epoch 262: loss improved from 1.61359 to 1.61270, saving model to /content/drive/MyDrive/all/ML/weights/weights_epoch_262_loss_1.6127.hdf5\n","202/202 [==============================] - 57s 282ms/step - loss: 1.6127\n","Epoch 263/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6133\n","Epoch 263: loss did not improve from 1.61270\n","202/202 [==============================] - 55s 270ms/step - loss: 1.6133\n","Epoch 264/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6125\n","Epoch 264: loss improved from 1.61270 to 1.61251, saving model to /content/drive/MyDrive/all/ML/weights/weights_epoch_264_loss_1.6125.hdf5\n","202/202 [==============================] - 56s 277ms/step - loss: 1.6125\n","Epoch 265/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6110\n","Epoch 265: loss improved from 1.61251 to 1.61098, saving model to /content/drive/MyDrive/all/ML/weights/weights_epoch_265_loss_1.6110.hdf5\n","202/202 [==============================] - 55s 275ms/step - loss: 1.6110\n","Epoch 266/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6136\n","Epoch 266: loss did not improve from 1.61098\n","202/202 [==============================] - 55s 275ms/step - loss: 1.6136\n","Epoch 267/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6108\n","Epoch 267: loss improved from 1.61098 to 1.61084, saving model to /content/drive/MyDrive/all/ML/weights/weights_epoch_267_loss_1.6108.hdf5\n","202/202 [==============================] - 56s 275ms/step - loss: 1.6108\n","Epoch 268/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6128\n","Epoch 268: loss did not improve from 1.61084\n","202/202 [==============================] - 55s 274ms/step - loss: 1.6128\n","Epoch 269/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6123\n","Epoch 269: loss did not improve from 1.61084\n","202/202 [==============================] - 55s 274ms/step - loss: 1.6123\n","Epoch 270/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6109\n","Epoch 270: loss did not improve from 1.61084\n","202/202 [==============================] - 55s 274ms/step - loss: 1.6109\n","Epoch 271/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6098\n","My War and Peace:\n","ôte and the staff officer was standing beside him.\n","\n","“what a strange fellow is that i have been told that it is not a general\n","who has been abandoned and i have not allowed me to see you,” said\n","prince andrew with a smile.\n","\n","“i have not seen him and i have not seen him and i have not seen him\n","and i have not seen him.”\n","\n","“yes, yes,” replied prince andrew, “i have not seen him and i have\n","not seen him and i have not seen him and i have not seen him. i have\n","not seen him and i have not seen him and i have \n","\n","Epoch 271: loss improved from 1.61084 to 1.60980, saving model to /content/drive/MyDrive/all/ML/weights/weights_epoch_271_loss_1.6098.hdf5\n","202/202 [==============================] - 82s 406ms/step - loss: 1.6098\n","Epoch 272/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6109\n","Epoch 272: loss did not improve from 1.60980\n","202/202 [==============================] - 57s 280ms/step - loss: 1.6109\n","Epoch 273/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6110\n","Epoch 273: loss did not improve from 1.60980\n","202/202 [==============================] - 55s 270ms/step - loss: 1.6110\n","Epoch 274/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6120\n","Epoch 274: loss did not improve from 1.60980\n","202/202 [==============================] - 55s 274ms/step - loss: 1.6120\n","Epoch 275/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6103\n","Epoch 275: loss did not improve from 1.60980\n","202/202 [==============================] - 55s 273ms/step - loss: 1.6103\n","Epoch 276/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6110\n","Epoch 276: loss did not improve from 1.60980\n","202/202 [==============================] - 55s 275ms/step - loss: 1.6110\n","Epoch 277/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6105\n","Epoch 277: loss did not improve from 1.60980\n","202/202 [==============================] - 55s 274ms/step - loss: 1.6105\n","Epoch 278/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6101\n","Epoch 278: loss did not improve from 1.60980\n","202/202 [==============================] - 55s 274ms/step - loss: 1.6101\n","Epoch 279/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6082\n","Epoch 279: loss improved from 1.60980 to 1.60824, saving model to /content/drive/MyDrive/all/ML/weights/weights_epoch_279_loss_1.6082.hdf5\n","202/202 [==============================] - 56s 275ms/step - loss: 1.6082\n","Epoch 280/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6085\n","Epoch 280: loss did not improve from 1.60824\n","202/202 [==============================] - 56s 275ms/step - loss: 1.6085\n","Epoch 281/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6091\n","My War and Peace:\n","\" preceding and precident and precious and an infinite party of the project\n","gutenberg-tm license and redistributed the project gutenberg-tm\n","license to the project gutenberg-tm license and redistributed to you for\n","certain perms of the project gutenberg-tm license and redistributed to\n","you for certain permission of the project gutenberg-tm license and redistributed to the project gutenberg-tm license to when the project\n","gutenberg-tm license is a frogect gutenberg-tm electronic work and\n","permission fr\n","\n","Epoch 281: loss did not improve from 1.60824\n","202/202 [==============================] - 81s 403ms/step - loss: 1.6091\n","Epoch 282/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6085\n","Epoch 282: loss did not improve from 1.60824\n","202/202 [==============================] - 57s 280ms/step - loss: 1.6085\n","Epoch 283/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6067\n","Epoch 283: loss improved from 1.60824 to 1.60670, saving model to /content/drive/MyDrive/all/ML/weights/weights_epoch_283_loss_1.6067.hdf5\n","202/202 [==============================] - 55s 272ms/step - loss: 1.6067\n","Epoch 284/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6088\n","Epoch 284: loss did not improve from 1.60670\n","202/202 [==============================] - 56s 276ms/step - loss: 1.6088\n","Epoch 285/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6072\n","Epoch 285: loss did not improve from 1.60670\n","202/202 [==============================] - 55s 274ms/step - loss: 1.6072\n","Epoch 286/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6076\n","Epoch 286: loss did not improve from 1.60670\n","202/202 [==============================] - 55s 275ms/step - loss: 1.6076\n","Epoch 287/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6065\n","Epoch 287: loss improved from 1.60670 to 1.60648, saving model to /content/drive/MyDrive/all/ML/weights/weights_epoch_287_loss_1.6065.hdf5\n","202/202 [==============================] - 55s 274ms/step - loss: 1.6065\n","Epoch 288/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6057\n","Epoch 288: loss improved from 1.60648 to 1.60570, saving model to /content/drive/MyDrive/all/ML/weights/weights_epoch_288_loss_1.6057.hdf5\n","202/202 [==============================] - 55s 275ms/step - loss: 1.6057\n","Epoch 289/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6077\n","Epoch 289: loss did not improve from 1.60570\n","202/202 [==============================] - 55s 275ms/step - loss: 1.6077\n","Epoch 290/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6070\n","Epoch 290: loss did not improve from 1.60570\n","202/202 [==============================] - 55s 274ms/step - loss: 1.6070\n","Epoch 291/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6061\n","My War and Peace:\n",". and the same sort of the sound of the sounds of the sun was standing before the fire and the sound of the sounds of the sun was standing.\n","\n","“there now, the emperor!” he shouted, and he suddenly felt that the\n","soldier who had been sent for and to the right and the commander in\n","chief was seen. the soldiers were standing before the commander in chief\n","and his stort beat high and his head was still standing before\n","him. the soldiers were standing in the same way, and the soldiers\n","were standing in the s\n","\n","Epoch 291: loss did not improve from 1.60570\n","202/202 [==============================] - 82s 404ms/step - loss: 1.6061\n","Epoch 292/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6064\n","Epoch 292: loss did not improve from 1.60570\n","202/202 [==============================] - 57s 280ms/step - loss: 1.6064\n","Epoch 293/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6055\n","Epoch 293: loss improved from 1.60570 to 1.60547, saving model to /content/drive/MyDrive/all/ML/weights/weights_epoch_293_loss_1.6055.hdf5\n","202/202 [==============================] - 55s 271ms/step - loss: 1.6055\n","Epoch 294/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6050\n","Epoch 294: loss improved from 1.60547 to 1.60496, saving model to /content/drive/MyDrive/all/ML/weights/weights_epoch_294_loss_1.6050.hdf5\n","202/202 [==============================] - 56s 277ms/step - loss: 1.6050\n","Epoch 295/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6048\n","Epoch 295: loss improved from 1.60496 to 1.60484, saving model to /content/drive/MyDrive/all/ML/weights/weights_epoch_295_loss_1.6048.hdf5\n","202/202 [==============================] - 55s 274ms/step - loss: 1.6048\n","Epoch 296/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6043\n","Epoch 296: loss improved from 1.60484 to 1.60430, saving model to /content/drive/MyDrive/all/ML/weights/weights_epoch_296_loss_1.6043.hdf5\n","202/202 [==============================] - 56s 275ms/step - loss: 1.6043\n","Epoch 297/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6072\n","Epoch 297: loss did not improve from 1.60430\n","202/202 [==============================] - 55s 273ms/step - loss: 1.6072\n","Epoch 298/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6036\n","Epoch 298: loss improved from 1.60430 to 1.60356, saving model to /content/drive/MyDrive/all/ML/weights/weights_epoch_298_loss_1.6036.hdf5\n","202/202 [==============================] - 56s 275ms/step - loss: 1.6036\n","Epoch 299/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6074\n","Epoch 299: loss did not improve from 1.60356\n","202/202 [==============================] - 55s 274ms/step - loss: 1.6074\n","Epoch 300/300\n","202/202 [==============================] - ETA: 0s - loss: 1.6046\n","Epoch 300: loss did not improve from 1.60356\n","202/202 [==============================] - 55s 275ms/step - loss: 1.6046\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f9f687d0710>"]},"metadata":{},"execution_count":22}]}]}